{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SETTINGS FOR THE GENERATOR #####\n",
    "\n",
    "# Files to write to.\n",
    "data_file = \"../data/PrometheusDataSecond.csv\"\n",
    "results_file = \"../data/PrometheusAnswersSecond.csv\"\n",
    "\n",
    "# Number of records (lines in csv file) to generate\n",
    "num_records = 20000\n",
    "\n",
    "# Number of values to add to a checkpoint set. This simulates how many values are recorded by an instrument.\n",
    "num_values = 12\n",
    "\n",
    "# Range of values to generate.\n",
    "value_lower_limit = -50\n",
    "value_upper_limit = 50\n",
    "\n",
    "# Histogram boundaries for buckets. Buckets in the Go SDK include \"lower\" buckets -- For example, if values are from 0 to 1\n",
    "# and there is a boundary at 0.5, the buckets would be (-int, 0.5) and (-inf, +inf) instead of (-inf, 0.5), [0.5, +inf]\n",
    "histogram_boundaries = [-25, 0, 25]\n",
    "\n",
    "# Quantiles for distributions.\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "\n",
    "# List of all aggregation types in the OTel Go SDK.\n",
    "aggregations = [\"hist\", \"dist\", \"sum\", \"mmsc\", \"lval\"]\n",
    "# aggregations = [\"dist\"]\n",
    "\n",
    "# A 2D dictionary of answers. Rows represent aggregation types and columns hold properties (name, description, label).\n",
    "# Each individual dictionary element is a list of 11 elements, which represent:\n",
    "# 0: Final Balue (sum / last value)\n",
    "# 1. Min\n",
    "# 2. Max\n",
    "# 3. Count\n",
    "# 4. (-inf, -25) bucket\n",
    "# 5. (-inf, 0) bucket \n",
    "# 6. (-inf, 25) bucket\n",
    "# 7. (-inf, +inf) bucket\n",
    "# 8. 0.25 quantile\n",
    "# 9. 0.5 quantile\n",
    "# 10. 0.75 quantile.\n",
    "answers = defaultdict(lambda: defaultdict(lambda: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### GENERATING DATA FILE #####\n",
    "\n",
    "# Open the data file to write to.\n",
    "f = open(data_file, \"w\")\n",
    "\n",
    "# Write `num_records` records to the file.\n",
    "for i in range(num_records):\n",
    "    # Randomly select an aggregation type.\n",
    "    agg_type = random.choice(aggregations)\n",
    "\n",
    "    # Create unique strings for the name, description, and label.\n",
    "    name = f\"p2name{i}_{agg_type}\"\n",
    "    label = f\"{{key{i}:value{i}}}\"\n",
    "\n",
    "    # Create a properties string that identifies the record with the name, description, and label.\n",
    "    agg_properties = f\"{name},{label}\"\n",
    "\n",
    "    # Generate a list of `num_values` random values that will be used to update the CheckpointSet.\n",
    "    values = random.sample(range(value_lower_limit, value_upper_limit), num_values)\n",
    "    \n",
    "    # values = random.sample(range(0, value_upper_limit), num_values)\n",
    "\n",
    "    # Write different types of records depending on the aggregation type.\n",
    "    record = f\"{agg_type}|{str(values).replace(' ', '')}|{agg_properties}\"\n",
    "    if agg_type == \"sum\":\n",
    "        # Final value (sum).\n",
    "        answers[\"sum\"][agg_properties][0] = sum(values)\n",
    "\n",
    "    elif agg_type == \"lval\":\n",
    "        # Final value (last value).\n",
    "        answers[\"lval\"][agg_properties][0] = values[len(values) - 1]\n",
    "\n",
    "    elif agg_type == \"mmsc\":\n",
    "        # Final value (sum), min, max, and count.\n",
    "        answers[\"mmsc\"][agg_properties][0] = sum(values)\n",
    "        answers[\"mmsc\"][agg_properties][1] = min(values)\n",
    "        answers[\"mmsc\"][agg_properties][2] = max(values)\n",
    "        answers[\"mmsc\"][agg_properties][3] = num_values\n",
    "\n",
    "    # Distribution aggregations are MinMaxSumCount aggregations with quantiles.\n",
    "    elif agg_type == \"dist\":\n",
    "        # Final value (sum), min, max, and count.\n",
    "        answers[\"dist\"][agg_properties][0] = sum(values)\n",
    "        answers[\"dist\"][agg_properties][1] = min(values)\n",
    "        answers[\"dist\"][agg_properties][2] = max(values)\n",
    "        answers[\"dist\"][agg_properties][3] = num_values\n",
    "\n",
    "        # Quantiles are calculated using numpy.\n",
    "        values_numpy = np.array(values)\n",
    "        answers[\"dist\"][agg_properties][8] = int(np.quantile(values_numpy, quantiles[0], interpolation='higher'))\n",
    "        answers[\"dist\"][agg_properties][9] = int(np.quantile(values_numpy, quantiles[1], interpolation='higher'))\n",
    "        answers[\"dist\"][agg_properties][10] = int(np.quantile(values_numpy, quantiles[2], interpolation='higher'))\n",
    "        \n",
    "    elif agg_type == \"hist\":\n",
    "        # Final value (sum).\n",
    "        answers[\"hist\"][agg_properties][0] = sum(values)\n",
    "\n",
    "        # Count.\n",
    "        answers[\"hist\"][agg_properties][3] = num_values\n",
    "\n",
    "        # (-inf, -25) bucket.\n",
    "        answers[\"hist\"][agg_properties][4] = len([i for i in values if i < -25])\n",
    "\n",
    "        # (-inf, 0) bucket\n",
    "        answers[\"hist\"][agg_properties][5] = len([i for i in values if i < 0])\n",
    "\n",
    "        # (-inf, 25) bucket\n",
    "        answers[\"hist\"][agg_properties][6] = len([i for i in values if i < 25])\n",
    "\n",
    "        # (-inf, +inf) bucket\n",
    "        answers[\"hist\"][agg_properties][7] = num_values\n",
    "\n",
    "    # Write the record to the file.\n",
    "    f.write(record + \"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GENERATING ANSWER FILE #####\n",
    "f = open(results_file, 'w+')\n",
    "\n",
    "# Iterate through every record in the answer dictionary. Note that order is not constant in a dictionary so the csv\n",
    "# file may not be in order index wise.\n",
    "for agg_type in answers:\n",
    "    for agg_properties in answers[agg_type]:\n",
    "        value = answers[agg_type][agg_properties][0]\n",
    "        agg_min = answers[agg_type][agg_properties][1]\n",
    "        agg_max = answers[agg_type][agg_properties][2]\n",
    "        count = answers[agg_type][agg_properties][3]\n",
    "        bucket_0 = answers[agg_type][agg_properties][4]\n",
    "        bucket_1 = answers[agg_type][agg_properties][5]\n",
    "        bucket_2 = answers[agg_type][agg_properties][6]\n",
    "        bucket_3 = answers[agg_type][agg_properties][7]\n",
    "        quantile_0 = answers[agg_type][agg_properties][8]\n",
    "        quantile_1 = answers[agg_type][agg_properties][9]\n",
    "        quantile_2 = answers[agg_type][agg_properties][10]\n",
    "\n",
    "        # Prepare a record (row in csv file) that will be written to the csv file.\n",
    "        record = \"\"\n",
    "\n",
    "        # Create records based on what the aggregation type.\n",
    "        if agg_type == \"sum\":\n",
    "            record = f\"{agg_properties}|{agg_type}|{value}\"\n",
    "        elif agg_type == \"lval\":\n",
    "            record = f\"{agg_properties}|{agg_type}|{value}\"\n",
    "        elif agg_type == \"mmsc\":\n",
    "            record = f\"{agg_properties}|{agg_type}|{value}|{agg_min}|{agg_max}|{count}\"\n",
    "        elif agg_type == \"dist\":\n",
    "            record = f\"{agg_properties}|{agg_type}|{value}|{agg_min}|{agg_max}|{count}|{{{quantile_0},{quantile_1},{quantile_2}}}\"\n",
    "        elif agg_type == \"hist\":\n",
    "            record = f\"{agg_properties}|{agg_type}|{value}|{count}|{{{bucket_0},{bucket_1},{bucket_2},{bucket_3}}}\"\n",
    "\n",
    "        # Write the full record to the csv file. \n",
    "        f.write(record + \"\\n\")\n",
    "\n",
    "# Save the records so it can be sorted later.\n",
    "f.seek(0)\n",
    "data = f.readlines()\n",
    "    \n",
    "# Close the file after writing.\n",
    "f.close()\n",
    "\n",
    "# Define custom key function so records are sorted based on its index.\n",
    "def record_index(record):\n",
    "    # Record always starts with \"p1name<index>_\". The index is retrieved using substrings.\n",
    "    underscore_index = record.index('_')\n",
    "    record_name = record[:underscore_index]\n",
    "    return int(record_name[6:])\n",
    "\n",
    "# Sort the data and then write it back to the file.\n",
    "data = sorted(data, key=record_index)\n",
    "f = open(results_file, 'w')\n",
    "for record in data:\n",
    "    f.write(record)\n",
    "\n",
    "# Close the file after writing.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1598619244085"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}